
/*
Allowed transitions:
        CRASHED -----------> RECOVERING -------------> ONLINE;
	/|\                                              |
         +-----------------------------------------------+

Timelines and periods:

st=ONLINE     st=CRASHED             st=RECOVERING          st=ONLINE
|-------X-----|----------------------|----------------------|--------> t
        |        ("boot" period)         ("grace" period)     ("normal" mode)
        |
     (actual crash)

*/


// Types -- verified by invariants or a type system (if there any).
struct redo_state_item {
	fid  node;
	bool is_done;
};

// In-memory states (state machines)
variable: redo_state, state space: any possible value of redo_state_item[N],
	where N depends on @T and it is in the range 0..NR_NODES.
variable: HA; // opaque object that generates HA events
variable: NETWORK; // opaque object that sends/receives REDO messages
variable: DTM; // opaque object that wraps around DTM log and CAS service

/* TODO: redo_state has to be a part of separate array of variables
	that represent volatile state of each participant
*/

// Transistions of in-memory states

// This function affects redo_state variable
redo_state.on_ha_event(RECOVERING self) {
	assume: HA.prev_state() == CRASHED;

	redo_state = HA.get_online_dones().map(\n -> (n.fid, false));
}

// This function affects only NETWORK variable
(NETWORK).on_ha_event(!ONLINE other) {
	assume: self != other;
	if (HA.is_recovering(self)) {
		redo_state.remove(other.fid);
		return;
	}
	// TODO: This branch should be moved
	// outside of the "event handler"
	// because it blocks the execution
	// of the states until all the log
	// records are processed.
	// Because of that we must assume
	// that the state of this node
	// does not change, as well as
	// the state of all the other nodes.
	if (HA.is_online(self) && HA.is_recovering(other)) {
		for record in DTM.log {
			if !record.has_pa(other) {
				contunue;
			}
			// see the TODO.
			assume: HA@t = HA@t+1.
			msg.src = self;
			msg.tgt = other;
			msg.dtx = record.dtx;
			NETWORK.send(msg);
			await NETWORK.recv(ack);
			// Execution is synchrnonous but
			// we still have to match acks.
			assume: ack.dtx.tx_id == msg.dtx.tx_id.
		}
	}
}

// This function affects DTM, NETWORK and HA variables
(NETWORK|DTM|HA).on_recv(REDO msg) {
	assume: The message was sent to us.
	assume: Execution is synchronous: acks sent only after a message
	is processed; there is no way to execute the last record
	before all the previous records are executed.
	assume: HA.is_online(msg.src).
	
	DTM.apply(msg);
	redo_state[msg.src].is_done = msg.is_last;
	ack = { .dtx = msg.dtx, .reply = msg.reply };
	await NETWORK.send(msg); // may include a reply, see DTM.apply

	if redo_state[msg.src].is_done {
		redo_state.remove(msg.src);
	}

	if redo_state.is_empty() {
		// The node "self" has been fully recovered.
		HA.consider_st_transition(self, ONLINE, now())
	}
}

// This function affect only the state of DTM variable
DTM.apply(msg) {
	record = DTM.lookup(msg.tx_id())
	if record.is_none() {
		msg.reply = DTM.CAS.execute(msg);
	} else {
		if msg.src.is_reply_required() {
			msg.reply = record.reply;
		}
	}
	DTM.log_update_state(msg.tx_id(), msg.states());
	async DTM.log_commit(msg.tx_id());
}

